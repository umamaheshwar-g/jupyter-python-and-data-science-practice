{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTJmsXnXQKbG"
   },
   "source": [
    "## Keras -- MLPs on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8880,
     "status": "ok",
     "timestamp": 1532670072534,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "2UILABPAQKbH",
    "outputId": "10fbb305-017f-45e7-ab0c-8787e2224880"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b0428a0fcc2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomNormal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\n",
    "from keras.utils import np_utils \n",
    "from keras.datasets import mnist \n",
    "import seaborn as sns\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOO-TM_7QKbM"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4700,
     "status": "ok",
     "timestamp": 1532670084617,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "TKmYKnibQKbQ",
    "outputId": "d861b5ef-2bba-4884-fec3-43f1b6e5646a"
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1532670089916,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "CCwnZae-QKbT",
    "outputId": "b5f379d4-7ebc-4112-96c5-1a4c2ab4a97c"
   },
   "outputs": [],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
    "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlotuCmoQKbW"
   },
   "outputs": [],
   "source": [
    "# if you observe the input shape its 2 dimensional vector\n",
    "# for each image we have a (28*28) vector\n",
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1532670095751,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "8JvpNJy4QKbY",
    "outputId": "cf0b2d6d-4976-45d3-a4ad-53b2ba3eed49"
   },
   "outputs": [],
   "source": [
    "# after converting the input images from 3d to 2d vectors\n",
    "\n",
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
    "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1532670101067,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "qvuaHDk0QKbb",
    "outputId": "1e5d1263-db82-4799-d47b-8a991bc2c89a"
   },
   "outputs": [],
   "source": [
    "# An example data point\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfohtdKPQKbd"
   },
   "outputs": [],
   "source": [
    "# if we observe the above matrix each cell is having a value between 0-255\n",
    "# before we move to apply machine learning algorithms lets try to normalize the data\n",
    "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1532670108312,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "4C-dmsXJQKbf",
    "outputId": "39118d5d-7c79-4f3e-c1f8-2f921de2b59d"
   },
   "outputs": [],
   "source": [
    "# example data point after normlizing\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1026,
     "status": "ok",
     "timestamp": 1532670116894,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "3Ruu-vXzQKbi",
    "outputId": "95160c17-cdc3-4127-c834-e64ce0ac9cc1"
   },
   "outputs": [],
   "source": [
    "# here we are having a class number for each image\n",
    "print(\"Class label of first image :\", y_train[0])\n",
    "\n",
    "# lets convert this into a 10 dimensional vector\n",
    "# ex: consider an image is 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "# this conversion needed for MLPs \n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10) \n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"After converting the output into a vector : \",Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0pWB6UyQKbk"
   },
   "source": [
    "<h2>  Softmax classifier  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLAGMubCQKbm"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "# The Sequential model is a linear stack of layers.\n",
    "# you can create a Sequential model by passing a list of layer instances to the constructor:\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(32, input_shape=(784,)),\n",
    "#     Activation('relu'),\n",
    "#     Dense(10),\n",
    "#     Activation('softmax'),\n",
    "# ])\n",
    "\n",
    "# You can also simply add layers via the .add() method:\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, input_dim=784))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "###\n",
    "\n",
    "# https://keras.io/layers/core/\n",
    "\n",
    "# keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
    "# bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "# kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias) where\n",
    "# activation is the element-wise activation function passed as the activation argument, \n",
    "# kernel is a weights matrix created by the layer, and \n",
    "# bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "\n",
    "# output = activation(dot(input, kernel) + bias)  => y = activation(WT. X + b)\n",
    "\n",
    "####\n",
    "\n",
    "# https://keras.io/activations/\n",
    "\n",
    "# Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers:\n",
    "\n",
    "# from keras.layers import Activation, Dense\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "# This is equivalent to:\n",
    "# model.add(Dense(64, activation='tanh'))\n",
    "\n",
    "# there are many activation functions ar available ex: tanh, relu, softmax\n",
    "\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0s7jzhVQKbn"
   },
   "outputs": [],
   "source": [
    "# some model parameters\n",
    "\n",
    "output_dim = 10\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 128 \n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdQg5wGDQKbr"
   },
   "outputs": [],
   "source": [
    "# start building a model\n",
    "model = Sequential()\n",
    "\n",
    "# The model needs to know what input shape it should expect. \n",
    "# For this reason, the first layer in a Sequential model \n",
    "# (and only the first, because following layers can do automatic shape inference)\n",
    "# needs to receive information about its input shape. \n",
    "# you can use input_shape and input_dim to pass the shape of input\n",
    "\n",
    "# output_dim represent the number of nodes need in that layer\n",
    "# here we have 10 nodes\n",
    "\n",
    "model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43776,
     "status": "ok",
     "timestamp": 1532670180018,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "EVA11VpmQKbt",
    "outputId": "08359e28-6c25-49ff-c806-248b1fa79a25"
   },
   "outputs": [],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method\n",
    "\n",
    "# It receives three arguments:\n",
    "# An optimizer. This could be the string identifier of an existing optimizer , https://keras.io/optimizers/\n",
    "# A loss function. This is the objective that the model will try to minimize., https://keras.io/losses/\n",
    "# A list of metrics. For any classification problem you will want to set this to metrics=['accuracy'].  https://keras.io/metrics/\n",
    "\n",
    "\n",
    "# Note: when using the categorical_crossentropy loss, your targets should be in categorical format \n",
    "# (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except \n",
    "# for a 1 at the index corresponding to the class of the sample).\n",
    "\n",
    "# that is why we converted out labels into vectors\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Keras models are trained on Numpy arrays of input data and labels. \n",
    "# For training a model, you will typically use the  fit function\n",
    "\n",
    "# fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "# validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "# validation_steps=None)\n",
    "\n",
    "# fit() function Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "# it returns A History object. Its History.history attribute is a record of training loss values and \n",
    "# metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# https://github.com/openai/baselines/issues/20\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1679,
     "status": "ok",
     "timestamp": 1532671653039,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "HNpwTMHcQKbw",
    "outputId": "d4b72284-e854-4931-9e3c-194cde835168"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eh4VWYrHQKbz"
   },
   "source": [
    " <h3>  MLP + Sigmoid activation + SGDOptimizer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1532672535990,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "7rzbngqHQKbz",
    "outputId": "c7b2d034-a61d-4676-91ca-1e2f0c8a20c0"
   },
   "outputs": [],
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_sigmoid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50953,
     "status": "ok",
     "timestamp": 1532672588508,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "48vVImSpQKb5",
    "outputId": "989df292-6e16-4eca-cfcb-b193ca431f72"
   },
   "outputs": [],
   "source": [
    "model_sigmoid.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2060,
     "status": "ok",
     "timestamp": 1532672590601,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "6ffjzr8hQKb8",
    "outputId": "8caf663e-e8cc-4c1e-9fee-278ab9591642"
   },
   "outputs": [],
   "source": [
    "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2682,
     "status": "ok",
     "timestamp": 1532672813648,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "Ejn01XXdQKb-",
    "outputId": "d301a744-1e86-4c2c-8e86-ea233376d0b7"
   },
   "outputs": [],
   "source": [
    "w_after = model_sigmoid.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ExLv_CAeQKcA"
   },
   "source": [
    "<h2>MLP + Sigmoid activation + ADAM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62441,
     "status": "ok",
     "timestamp": 1532672891495,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "w9BtnNGaQKcD",
    "outputId": "9077226e-e62a-440f-fc87-439b21e31d70"
   },
   "outputs": [],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AslSnqQ2QKcF",
    "outputId": "3bf10216-1082-42f1-dbb5-2910e779d524"
   },
   "outputs": [],
   "source": [
    "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1532674029296,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "//lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAAAWk/jhKHALKaHag/s50-c-k-no/photo.jpg",
      "userId": "116292885805316472049"
     },
     "user_tz": -330
    },
    "id": "HEp-AZCSQKcI",
    "outputId": "f1416fcd-c07c-43ec-906e-2a775972e4a7"
   },
   "outputs": [],
   "source": [
    "w_after = model_sigmoid.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRVrzqvSQKcL"
   },
   "source": [
    "<h2> MLP + ReLU +SGD </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8lG2jzmQKcM",
    "outputId": "72a68439-c243-4569-86b9-f636757c60f7"
   },
   "outputs": [],
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "# https://arxiv.org/pdf/1707.09725.pdf#page=95\n",
    "# for relu layers\n",
    "# If we sample weights from a normal distribution N(0,σ) we satisfy this condition with σ=√(2/(ni). \n",
    "# h1 =>  σ=√(2/(fan_in) = 0.062  => N(0,σ) = N(0,0.062)\n",
    "# h2 =>  σ=√(2/(fan_in) = 0.125  => N(0,σ) = N(0,0.125)\n",
    "# out =>  σ=√(2/(fan_in+1) = 0.120  => N(0,σ) = N(0,0.120)\n",
    "\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhtoviFKQKcP",
    "outputId": "e25de732-19a7-4178-d784-411170e6d810"
   },
   "outputs": [],
   "source": [
    "model_relu.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rKzoKxgQKcS",
    "outputId": "7893c859-5d0d-4cbb-ef05-d7dd854e325c"
   },
   "outputs": [],
   "source": [
    "score = model_relu.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z386BnBlQKcV",
    "outputId": "dbfc21b4-4c17-4c29-86f0-9ea53c26d112"
   },
   "outputs": [],
   "source": [
    "w_after = model_relu.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ccmfiVGQKcc"
   },
   "source": [
    "<h2> MLP + ReLU + ADAM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CtwrinkQKcc",
    "outputId": "c46c7912-e77b-48c5-a506-b90cc13ba9f2"
   },
   "outputs": [],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "print(model_relu.summary())\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niCdh2TUQKce",
    "outputId": "9620cc68-260a-4f70-e2a2-2296d55cade6"
   },
   "outputs": [],
   "source": [
    "score = model_relu.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDtptoSnQKcf",
    "outputId": "4fd88cc4-6452-4f28-970f-bd7a0c5fe462"
   },
   "outputs": [],
   "source": [
    "w_after = model_relu.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjduBU7hQKch"
   },
   "source": [
    "<h2> MLP + Batch-Norm on hidden Layers + AdamOptimizer </2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGHnPnoTQKci",
    "outputId": "8abd1dfb-b838-47f8-9e9b-0a4a757bfd8a"
   },
   "outputs": [],
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "# https://intoli.com/blog/neural-network-initialization/ \n",
    "# If we sample weights from a normal distribution N(0,σ) we satisfy this condition with σ=√(2/(ni+ni+1). \n",
    "# h1 =>  σ=√(2/(ni+ni+1) = 0.039  => N(0,σ) = N(0,0.039)\n",
    "# h2 =>  σ=√(2/(ni+ni+1) = 0.055  => N(0,σ) = N(0,0.055)\n",
    "# h1 =>  σ=√(2/(ni+ni+1) = 0.120  => N(0,σ) = N(0,0.120)\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model_batch = Sequential()\n",
    "\n",
    "model_batch.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_batch.add(BatchNormalization())\n",
    "\n",
    "model_batch.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_batch.add(BatchNormalization())\n",
    "\n",
    "model_batch.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_batch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMPo5fcUQKcm",
    "outputId": "345fa9de-3920-49c3-b03e-2ba99ddfb7c7"
   },
   "outputs": [],
   "source": [
    "model_batch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_batch.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HThyBcHUQKcn",
    "outputId": "3da2f50e-c25f-4903-da11-d294ec1a63b8"
   },
   "outputs": [],
   "source": [
    "score = model_batch.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ilj0es2yQKcp",
    "outputId": "55ee6f5e-c253-4cf2-fe1e-4d9be82e1c88"
   },
   "outputs": [],
   "source": [
    "w_after = model_batch.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWYP8-3pQKct"
   },
   "source": [
    "<h2> 5. MLP + Dropout + AdamOptimizer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJj0hu0-QKct",
    "outputId": "674bedfc-e833-4fb7-f0d6-908fb9906c36"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5pc4W_9QKcw",
    "outputId": "fc6c250a-49f9-46d7-de24-ae1977ea2ccc"
   },
   "outputs": [],
   "source": [
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5WcfQRFQKc0",
    "outputId": "67d7cea2-34bc-41f4-a62e-53710bd6100b"
   },
   "outputs": [],
   "source": [
    "score = model_drop.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2N2u7xoQKc2",
    "outputId": "fb67995c-2b23-4967-c398-3a621d1b63f4"
   },
   "outputs": [],
   "source": [
    "w_after = model_drop.get_weights()\n",
    "\n",
    "h1_w = w_after[0].flatten().reshape(-1,1)\n",
    "h2_w = w_after[2].flatten().reshape(-1,1)\n",
    "out_w = w_after[4].flatten().reshape(-1,1)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Weight matrices after model trained\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h1_w,color='b')\n",
    "plt.xlabel('Hidden Layer 1')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=h2_w, color='r')\n",
    "plt.xlabel('Hidden Layer 2 ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Trained model Weights\")\n",
    "ax = sns.violinplot(y=out_w,color='y')\n",
    "plt.xlabel('Output Layer ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ayBTjaZGQKc6"
   },
   "source": [
    "<h2> Hyper-parameter tuning of Keras models using Sklearn </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k1L9fZcQKc6"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "def best_hyperparameters(activ):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activ, input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "    model.add(Dense(128, activation=activ, kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mj1klnwWQKc7"
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "activ = ['sigmoid','relu']\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=best_hyperparameters, epochs=nb_epoch, batch_size=batch_size, verbose=0)\n",
    "param_grid = dict(activ=activ)\n",
    "\n",
    "# if you are using CPU\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# if you are using GPU dont use the n_jobs parameter\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UiW9qkmQKc8",
    "outputId": "625e907e-e347-4826-953d-e09c26a2e397"
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Keras_Mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
